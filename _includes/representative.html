<ul>
<li><a href="https://arxiv.org/abs/2504.05419v1">Reasoning Models Know When They're Right: Probing Hidden States for Self-Verification</a>.<br>Anqi Zhang, Yulin Chen, Jane Pan, Chen Zhao, Aurojit Panda, Jinyang Li and He He. <i>arXiv:2504.05419 preprint</i>, 2025.  [<a href="javascript:copy(div1000, bib1000)">bib</a>]<br>
<div id="div1000"></div><div id="bib1000" style="display:none">
<div class="bib">
<pre>
@article{zhang2025reasoning,
        author={Anqi Zhang and Yulin Chen and Jane Pan and Chen Zhao and Aurojit Panda and Jinyang Li and He He},
        title={Reasoning Models Know When They're Right: Probing Hidden States for Self-Verification},
        journal={arXiv:2504.05419},
        year={2025}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/pdf/2412.04703">Transformers Struggle to Learn to Search</a>.<br>Abulhair Saparov, Srushti Pawar, Shreyas Pimpalgaonkar, Nitish Joshi, Richard Yuanzhe Pang, Vishakh Padmakumar, Seyed Mehran Kazemi, Najoung Kim* and He He*. <i>International Conference on Learning Representations (ICLR)</i>, 2025.  [<a href="javascript:copy(div1002, bib1002)">bib</a>]<br>
<div id="div1002"></div><div id="bib1002" style="display:none">
<div class="bib">
<pre>
@inproceedings{saparov2025search,
        author={Abulhair Saparov and Srushti Pawar and Shreyas Pimpalgaonkar and Nitish Joshi and Richard Yuanzhe Pang and Vishakh Padmakumar and Seyed Mehran Kazemi and Najoung Kim and He He},
        title={Transformers Struggle to Learn to Search},
        booktitle={International Conference on Learning Representations (ICLR)},
        year={2025}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/pdf/2409.12822">Language Models Learn to Mislead Humans via RLHF</a>.<br>Jiaxin Wen, Ruiqi Zhong, Akbir Khan, Ethan Perez, Jacob Steinhardt, Minlie Huang, Sam Boman, He He and Shi Feng. <i>International Conference on Learning Representations (ICLR)</i>, 2025.  [<a href="javascript:copy(div1004, bib1004)">bib</a>]<br>
<div id="div1004"></div><div id="bib1004" style="display:none">
<div class="bib">
<pre>
@inproceedings{wen2025language,
        author={Jiaxin Wen and Ruiqi Zhong and Akbir Khan and Ethan Perez and Jacob Steinhardt and Minlie Huang and Sam Boman and He He and Shi Feng},
        title={Language Models Learn to Mislead Humans via RLHF},
        booktitle={International Conference on Learning Representations (ICLR)},
        year={2025}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/pdf/2402.12530">Parallel Structures in Pre-training Data Yield In-Context Learning</a>.<br>Yanda Chen, Chen Zhao, Zhou Yu, Kathleen McKeown and He He. <i>Association for Computational Linguistics (ACL)</i>, 2024.  [<a href="javascript:copy(div1012, bib1012)">bib</a>]
[<a href="https://github.com/yandachen/ParallelStructuresICL">code</a>]<br>
<div id="div1012"></div><div id="bib1012" style="display:none">
<div class="bib">
<pre>
@inproceedings{chen2024parallel,
        author={Yanda Chen and Chen Zhao and Zhou Yu and Kathleen McKeown and He He},
        title={Parallel Structures in Pre-training Data Yield In-Context Learning},
        booktitle={Association for Computational Linguistics (ACL)},
        year={2024}
}
</pre>
</div>
</div> </li>
<li><a href="https://www.nature.com/articles/s41586-023-06747-5">Solving Olympiad Geometry without Human Demonstrations</a>.<br>Trieu Trinh, Yuhuai Wu, Quoc V Le, He He and Thang Luong. <i>Nature (Nature)</i>, 2024.  [<a href="javascript:copy(div1014, bib1014)">bib</a>]<br>
<div id="div1014"></div><div id="bib1014" style="display:none">
<div class="bib">
<pre>
@article{trinh2024geometry,
        author={Trieu Trinh and Yuhuai Wu and Quoc V Le and He He and Thang Luong},
        title={Solving Olympiad Geometry without Human Demonstrations},
        journal={Nature},
        volume={625},
        pages={476--482},
        year={2024}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/pdf/2310.18168">Personas as a Way to Model Truthfulness in Language Models</a>.<br>Nitish Joshi*, Javier Rando*, Abulhair Saparov, Najoung Kim and He He. <i>Empirical Methods in Natural Language Processing (EMNLP)</i>, 2024.  [<a href="javascript:copy(div1017, bib1017)">bib</a>]<br>
<div id="div1017"></div><div id="bib1017" style="display:none">
<div class="bib">
<pre>
@inproceedings{joshi2024persona,
        author={Nitish Joshi and Javier Rando and Abulhair Saparov and Najoung Kim and He He},
        title={Personas as a Way to Model Truthfulness in Language Models},
        booktitle={Empirical Methods in Natural Language Processing (EMNLP)},
        year={2024}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/abs/2309.05196">Does Writing with Language Models Reduce Content Diversity?</a>.<br>Vishakh Padmakumar and He He. <i>International Conference on Learning Representations (ICLR)</i>, 2024.  [<a href="javascript:copy(div1018, bib1018)">bib</a>]
[<a href="https://github.com/vishakhpk/hai-diversity">code</a>]<br>
<div id="div1018"></div><div id="bib1018" style="display:none">
<div class="bib">
<pre>
@inproceedings{padmakumar2024writing,
        author={Vishakh Padmakumar and He He},
        title={Does Writing with Language Models Reduce Content Diversity?},
        booktitle={International Conference on Learning Representations (ICLR)},
        year={2024}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/pdf/2307.08678.pdf">Do Models Explain Themselves? Counterfactual Simulatability of Natural Language Explanations </a>.<br>Yanda Chen, Ruiqi Zhong, Narutatsu Ri, Chen Zhao, He He, Jacob Steinhardt, Zhou Yu and Kathleen McKeown. <i>International Conference on Machine Learning (ICML)</i>, 2024.  <font color="red">Spotlight</font> [<a href="javascript:copy(div1020, bib1020)">bib</a>]
[<a href="https://github.com/yandachen/CounterfactualSimulatability">code</a>]<br>
<div id="div1020"></div><div id="bib1020" style="display:none">
<div class="bib">
<pre>
@inproceedings{chen2024do,
        author={Yanda Chen and Ruiqi Zhong and Narutatsu Ri and Chen Zhao and He He and Jacob Steinhardt and Zhou Yu and Kathleen McKeown},
        title={Do Models Explain Themselves? Counterfactual Simulatability of Natural Language Explanations },
        booktitle={International Conference on Machine Learning (ICML)},
        year={2024}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/abs/2305.15269">Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples</a>.<br>Abulhair Saparov, Richard Yuanzhe Pang, Vishakh Padmakumar, Nitish Joshi, Seyed Mehran Kazemi, Najoung Kim* and He He*. <i>Neural Information Processing Systems (NeurIPS)</i>, 2023.  [<a href="javascript:copy(div1024, bib1024)">bib</a>]
[<a href="https://github.com/asaparov/prontoqa">code</a>]<br>
<div id="div1024"></div><div id="bib1024" style="display:none">
<div class="bib">
<pre>
@inproceedings{saparov2023testing,
        author={Abulhair Saparov and Richard Yuanzhe Pang and Vishakh Padmakumar and Nitish Joshi and Seyed Mehran Kazemi and Najoung Kim and He He},
        title={Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples},
        booktitle={Neural Information Processing Systems (NeurIPS)},
        year={2023}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/abs/2211.08714">Reward Gaming in Conditional Text Generation</a>.<br>Richard Yuanzhe Pang, Vishakh Padmakumar, Thibault Sellam, Ankur P Parikh and He He. <i>Association for Computational Linguistics (ACL)</i>, 2023.  [<a href="javascript:copy(div1027, bib1027)">bib</a>]
[<a href="{% link /docs/presentation/reward-gaming-slides.pdf %}">talk</a>]<br>
<div id="div1027"></div><div id="bib1027" style="display:none">
<div class="bib">
<pre>
@inproceedings{pang2023reward,
        author={Richard Yuanzhe Pang and Vishakh Padmakumar and Thibault Sellam and Ankur P Parikh and He He},
        title={Reward Gaming in Conditional Text Generation},
        booktitle={Association for Computational Linguistics (ACL)},
        year={2023}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/pdf/2303.04562.pdf">Extrapolative Controlled Sequence Generation via Iterative Refinement </a>.<br>Vishakh Padmakumar, Richard Yuanzhe Pang, He He and Ankur P Parikh. <i>International Conference on Machine Learning (ICML)</i>, 2023.  [<a href="javascript:copy(div1028, bib1028)">bib</a>]
[<a href="https://github.com/vishakhpk/iter-extrapolation">code</a>]<br>
<div id="div1028"></div><div id="bib1028" style="display:none">
<div class="bib">
<pre>
@inproceedings{padmakumar2023extrapolative,
        author={Vishakh Padmakumar and Richard Yuanzhe Pang and He He and Ankur P Parikh},
        title={Extrapolative Controlled Sequence Generation via Iterative Refinement },
        booktitle={International Conference on Machine Learning (ICML)},
        year={2023}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/abs/2210.01240">Language Models are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought</a>.<br>Abulhair Saparov and He He. <i>International Conference on Learning Representations (ICLR)</i>, 2023.  [<a href="javascript:copy(div1031, bib1031)">bib</a>]
[<a href="http://github.com/asaparov/prontoqa">code</a>]
[<a href="{% link /docs/presentation/prontoqa-slides.pdf %}">talk</a>]<br>
<div id="div1031"></div><div id="bib1031" style="display:none">
<div class="bib">
<pre>
@inproceedings{saparov2023language,
        author={Abulhair Saparov and He He},
        title={Language Models are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought},
        booktitle={International Conference on Learning Representations (ICLR)},
        year={2023}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/pdf/2210.14011.pdf">Are All Spurious Features in Natural Language Alike? An Analysis through a Causal Lens</a>.<br>Nitish Joshi, Xiang Pan and He He. <i>Empirical Methods in Natural Language Processing (EMNLP)</i>, 2022.  [<a href="javascript:copy(div1033, bib1033)">bib</a>]
[<a href="https://github.com/joshinh/spurious-correlations-nlp">code</a>]
[<a href="{% link /docs/presentation/spurious-features-slides.pdf %}">talk</a>]<br>
<div id="div1033"></div><div id="bib1033" style="display:none">
<div class="bib">
<pre>
@inproceedings{joshi2022all,
        author={Nitish Joshi and Xiang Pan and He He},
        title={Are All Spurious Features in Natural Language Alike? An Analysis through a Causal Lens},
        booktitle={Empirical Methods in Natural Language Processing (EMNLP)},
        year={2022}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/abs/2110.07814">Meta-learning via Language Model In-context Tuning</a>.<br>Yanda Chen, Ruiqi Zhong, Sheng Zha, George Karypis and He He. <i>Association for Computational Linguistics (ACL)</i>, 2022.  [<a href="javascript:copy(div1041, bib1041)">bib</a>]
[<a href="https://github.com/yandachen/In-context-Tuning">code</a>]<br>
<div id="div1041"></div><div id="bib1041" style="display:none">
<div class="bib">
<pre>
@inproceedings{chen2022meta,
        author={Yanda Chen and Ruiqi Zhong and Sheng Zha and George Karypis and He He},
        title={Meta-learning via Language Model In-context Tuning},
        booktitle={Association for Computational Linguistics (ACL)},
        year={2022}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/abs/2107.00753">An Investigation of the (In)effectiveness of Counterfactually Augmented Data</a>.<br>Nitish Joshi and He He. <i>Association for Computational Linguistics (ACL)</i>, 2022.  [<a href="javascript:copy(div1043, bib1043)">bib</a>]
[<a href="https://github.com/joshinh/investigation-cad">code</a>]<br>
<div id="div1043"></div><div id="bib1043" style="display:none">
<div class="bib">
<pre>
@inproceedings{joshi2022investigation,
        author={Nitish Joshi and He He},
        title={An Investigation of the (In)effectiveness of Counterfactually Augmented Data},
        booktitle={Association for Computational Linguistics (ACL)},
        year={2022}
}
</pre>
</div>
</div> </li>
<li><a href="https://openreview.net/pdf?id=RovX-uQ1Hua">Text Generation by Learning from Demonstrations</a>.<br>Richard Yuanzhe Pang and He He. <i>International Conference on Learning Representations (ICLR)</i>, 2021.  [<a href="javascript:copy(div1047, bib1047)">bib</a>]
[<a href="https://github.com/yzpang/gold-off-policy-text-gen-iclr21">code</a>]
[<a href="{% link /docs/presentation/gold-slides.pdf %}">talk</a>]<br>
<div id="div1047"></div><div id="bib1047" style="display:none">
<div class="bib">
<pre>
@inproceedings{pang2021text,
        author={Richard Yuanzhe Pang and He He},
        title={Text Generation by Learning from Demonstrations},
        booktitle={International Conference on Learning Representations (ICLR)},
        year={2021}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/abs/2007.06778">An Empirical Study on Robustness to Spurious Correlations using Pre-trained Language Models</a>.<br>Lifu Tu, Garima Lalwani, Spandana Gella and He He. <i>Transaction of Association for Computational Linguistics (TACL)</i>, 2020.  [<a href="javascript:copy(div1048, bib1048)">bib</a>]
[<a href="https://github.com/lifu-tu/Study-NLP-Robustness">code</a>]<br>
<div id="div1048"></div><div id="bib1048" style="display:none">
<div class="bib">
<pre>
@article{tu2020empirical,
        author={Lifu Tu and Garima Lalwani and Spandana Gella and He He},
        title={An Empirical Study on Robustness to Spurious Correlations using Pre-trained Language Models},
        journal={TACL},
        volume={8},
        pages={},
        year={2020}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/abs/2005.03754">FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization</a>.<br>Esin Durmus, He He and Mona Diab. <i>Association for Computational Linguistics (ACL)</i>, 2020.  [<a href="javascript:copy(div1049, bib1049)">bib</a>]
[<a href="https://github.com/esdurmus/feqa">code</a>]
[<a href="https://slideslive.com/38929353/feqa-a-question-answering-evaluation-framework-for-faithfulness-assessment-in-abstractive-summarization">talk</a>]<br>
<div id="div1049"></div><div id="bib1049" style="display:none">
<div class="bib">
<pre>
@inproceedings{durmus2020feqa,
        author={Esin Durmus and He He and Mona Diab},
        title={FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization},
        booktitle={Association for Computational Linguistics (ACL)},
        year={2020}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/pdf/1908.10763.pdf">Unlearn Dataset Bias for Natural Language Inference by Fitting the Residual</a>.<br>He He, Sheng Zha and Haohan Wang. <i>EMNLP Workshop on DeepLo</i>, 2019.  [<a href="javascript:copy(div1051, bib1051)">bib</a>]
[<a href="https://github.com/hhexiy/debiased">code</a>]
[<a href="{% link /docs/presentation/2019_emnlp_deeplo_poster.pdf %}">poster</a>]<br>
<div id="div1051"></div><div id="bib1051" style="display:none">
<div class="bib">
<pre>
@inproceedings{he2019unlearn,
        author={He He and Sheng Zha and Haohan Wang},
        title={Unlearn Dataset Bias for Natural Language Inference by Fitting the Residual},
        booktitle={EMNLP Workshop on DeepLo},
        year={2019}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/pdf/1904.06828.pdf">Pun Generation with Surprise</a>.<br>He He*, Nanyun Peng* and Percy Liang. <i>North American Chapter of the Association for Computational Linguistics (NAACL)</i>, 2019.  [<a href="javascript:copy(div1052, bib1052)">bib</a>]
[<a href="https://github.com/hhexiy/pungen">code</a>]
[<a href="https://worksheets.codalab.org/worksheets/0x5a7d0fe35b144ad68998d74891a31ed6">codalab</a>]<br>
<div id="div1052"></div><div id="bib1052" style="display:none">
<div class="bib">
<pre>
@inproceedings{he2019pun,
        author={He He and Nanyun Peng and Percy Liang},
        title={Pun Generation with Surprise},
        booktitle={North American Chapter of the Association for Computational Linguistics (NAACL)},
        year={2019}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/abs/1808.09637">Decoupling Strategy and Generation in Negotiation Dialogues</a>.<br>He He, Derek Chen, Anusha Balakrishnan and Percy Liang. <i>Empirical Methods in Natural Language Processing (EMNLP)</i>, 2018.  [<a href="javascript:copy(div1055, bib1055)">bib</a>]
[<a href="https://stanfordnlp.github.io/cocoa/">project</a>]<br>
<div id="div1055"></div><div id="bib1055" style="display:none">
<div class="bib">
<pre>
@inproceedings{he2018decouple,
        author={He He and Derek Chen and Anusha Balakrishnan and Percy Liang},
        title={Decoupling Strategy and Generation in Negotiation Dialogues},
        booktitle={Empirical Methods in Natural Language Processing (EMNLP)},
        year={2018}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/pdf/1808.07036.pdf">QuAC: Question Answering in Context</a>.<br>Eunsol Choi*, He He*, Mohit Iyyer*, Mark Yatskar*, Wen-tau Yih, Yejin Choi, Percy Liang and Luke Zettlemoyer. <i>Empirical Methods in Natural Language Processing (EMNLP)</i>, 2018.  [<a href="javascript:copy(div1056, bib1056)">bib</a>]
[<a href="http://quac.ai">project</a>]<br>
<div id="div1056"></div><div id="bib1056" style="display:none">
<div class="bib">
<pre>
@inproceedings{choi2018quac,
        author={Eunsol Choi and He He and Mohit Iyyer and Mark Yatskar and Wen-tau Yih and Yejin Choi and Percy Liang and Luke Zettlemoyer},
        title={QuAC: Question Answering in Context},
        booktitle={Empirical Methods in Natural Language Processing (EMNLP)},
        year={2018}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/pdf/1805.04623.pdf">Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context</a>.<br>Urvashi Khandelwal, He He, Peng Qi and Dan Jurafsky. <i>Association for Computational Linguistics (ACL)</i>, 2018.  [<a href="javascript:copy(div1057, bib1057)">bib</a>]
[<a href="https://github.com/urvashik/lm-context-analysis">code</a>]<br>
<div id="div1057"></div><div id="bib1057" style="display:none">
<div class="bib">
<pre>
@inproceedings{khandelwal2018lm,
        author={Urvashi Khandelwal and He He and Peng Qi and Dan Jurafsky},
        title={Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context},
        booktitle={Association for Computational Linguistics (ACL)},
        year={2018}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/pdf/1804.06437.pdf">Delete, Retrieve, Generate: a Simple Approach to Sentiment and Style Transfer</a>.<br>Juncen Li, Robin Jia, He He and Percy Liang. <i>North American Chapter of the Association for Computational Linguistics (NAACL)</i>, 2018.  [<a href="javascript:copy(div1058, bib1058)">bib</a>]
[<a href="https://github.com/lijuncen/Sentiment-and-Style-Transfer">code</a>]<br>
<div id="div1058"></div><div id="bib1058" style="display:none">
<div class="bib">
<pre>
@inproceedings{li2018style,
        author={Juncen Li and Robin Jia and He He and Percy Liang},
        title={Delete, Retrieve, Generate: a Simple Approach to Sentiment and Style Transfer},
        booktitle={North American Chapter of the Association for Computational Linguistics (NAACL)},
        year={2018}
}
</pre>
</div>
</div> </li>
<li><a href="https://arxiv.org/pdf/1704.07130.pdf">Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings</a>.<br>He He, Anusha Balakrishnan, Mihail Eric and Percy Liang. <i>Association for Computational Linguistics (ACL)</i>, 2017.  [<a href="javascript:copy(div1059, bib1059)">bib</a>]
[<a href="https://stanfordnlp.github.io/cocoa/">project</a>]<br>
<div id="div1059"></div><div id="bib1059" style="display:none">
<div class="bib">
<pre>
@inproceedings{he2017symmetric,
        author={He He and Anusha Balakrishnan and Mihail Eric and Percy Liang},
        title={Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings},
        booktitle={Association for Computational Linguistics (ACL)},
        year={2017}
}
</pre>
</div>
</div> </li>
<li><a href="docs/papers/2016_icml_opponent.pdf">Opponent Modeling in Deep Reinforcement Learning</a>.<br>He He, Jordan Boyd-Graber, Kevin Kwok and Hal Daume III. <i>International Conference on Machine Learning (ICML)</i>, 2016.  [<a href="javascript:copy(div1061, bib1061)">bib</a>]
[<a href="https://github.com/hhexiy/opponent">code</a>]
[<a href="{% link /data/qb_data.tgz %}">data</a>]<br>
<div id="div1061"></div><div id="bib1061" style="display:none">
<div class="bib">
<pre>
@inproceedings{he2016opponent,
        author={He He and Jordan Boyd-Graber and Kevin Kwok and Hal {Daum\'{e} III}},
        title={Opponent Modeling in Deep Reinforcement Learning},
        booktitle={International Conference on Machine Learning (ICML)},
        year={2016}
}
</pre>
</div>
</div> </li>
<li><a href="docs/papers/ilp-bb.pdf">Learning to Search in Branch and Bound Algorithms</a>.<br>He He, Hal Daume III and Jason Eisner. <i>Neural Information Processing Systems (NeurIPS)</i>, 2014.  [<a href="javascript:copy(div1071, bib1071)">bib</a>]
[<a href="https://github.com/hhexiy/scip-dagger">code</a>]
[<a href="{% link /docs/presentation/ilp-bb-poster-nips2014.pdf %}">poster</a>]<br>
<div id="div1071"></div><div id="bib1071" style="display:none">
<div class="bib">
<pre>
@inproceedings{he2014bb,
        author={He He and Hal {Daum\'{e} III} and Jason Eisner},
        title={Learning to Search in Branch and Bound Algorithms},
        booktitle={Neural Information Processing Systems (NeurIPS)},
        year={2014}
}
</pre>
</div>
</div> </li>
<li><a href="docs/papers/depFeat.pdf">Dynamic Feature Selection for Dependency Parsing</a>.<br>He He, Hal Daume III and Jason Eisner. <i>Empirical Methods in Natural Language Processing (EMNLP)</i>, 2013.  [<a href="javascript:copy(div1073, bib1073)">bib</a>]
[<a href="{% link /docs/presentation/depFeat_screencast.mp4 %}">talk</a>]<br>
<div id="div1073"></div><div id="bib1073" style="display:none">
<div class="bib">
<pre>
@inproceedings{he2013dep,
        author={He He and Hal {Daum\'{e} III} and Jason Eisner},
        title={Dynamic Feature Selection for Dependency Parsing},
        booktitle={Empirical Methods in Natural Language Processing (EMNLP)},
        year={2013}
}
</pre>
</div>
</div> </li>
<li><a href="docs/papers/dynafea_im.pdf">Imitation Learning by Coaching</a>.<br>He He, Hal Daume III and Jason Eisner. <i>Neural Information Processing Systems (NeurIPS)</i>, 2012.  [<a href="javascript:copy(div1074, bib1074)">bib</a>]
[<a href="{% link /docs/presentation/dynafea_im_poster.pdf %}">poster</a>]<br>
<div id="div1074"></div><div id="bib1074" style="display:none">
<div class="bib">
<pre>
@inproceedings{he2012coaching,
        author={He He and Hal {Daum\'{e} III} and Jason Eisner},
        title={Imitation Learning by Coaching},
        booktitle={Neural Information Processing Systems (NeurIPS)},
        year={2012}
}
</pre>
</div>
</div> </li>
<li><a href="docs/papers/srgpr.pdf">Single Image Super-resolution using Gaussian Process Regression</a>.<br>He He and Wan-Chi Siu. <i>Computer Vision and Pattern Recognition (CVPR)</i>, 2011.  [<a href="javascript:copy(div1077, bib1077)">bib</a>]
[<a href="{% link /code/matlab_srgpr.zip %}">code</a>]
[<a href="{% link /docs/presentation/srgpr_slides.pdf %}">talk</a>]<br>
<div id="div1077"></div><div id="bib1077" style="display:none">
<div class="bib">
<pre>
@inproceedings{he2011superres,
        author={He He and Wan-Chi Siu},
        title={Single Image Super-resolution using Gaussian Process Regression},
        booktitle={Computer Vision and Pattern Recognition (CVPR)},
        year={2011}
}
</pre>
</div>
</div> </li>
</ul>
